#! /bin/sh 

############################################################################################################################
# SCENARIO 11 - RANDOM STAT() ON FILES - ONE (1) PROCESS
############################################################################################################################
# 11.01 OBJECTIVE
## To understand the file system performance of a random readdir() or stat() call with a large number of files in a large number of directories with one (1) process.
# 11.02 DESCRIPTION
## One (1) process performing a random readdir() or stat() with ten (10) million files located in ten (10) directories with one (1) million files per directory.
# Method for running the Scenario:
## 1. Create file system, mount, and tune.
## 2. Randomly make ten (10) directories. 
## 3. Randomly create in parallel one (1) million files in each of the ten (10) directories using at least one hundred (100) creation threads or processes.
## 4. Unmount file system.
## 5. Mount file system.
## 6. Start time counter.
## 7. Serial random walk using readdir() or stat() of all the files in each of the directories in a random order using only one (1) thread or process (this is the cold cache test).
## 8. Stop time counter.
## 9. Start time counter.
## 10. Serial random walk using readdir() or stat() of all the files in each of the directories in a random order using only one (1) thread or process (this is the warm cache test).
## 11. Stop time counter.
## 12. Repeat steps 4-11 at least three (3) times.
## 11.03 EXPECTED RESULTS
## No measurement is required but the performance numbers should be reported along with the test setup 
## and at least three (3) runs using cold cache and three (3) runs using warm cache. 
## The variance in reported performance should be low especially for the warm cache results.
############################################################################################################################

#PBS -q batch
#PBS -A stf006
#PBS -N S04
#PBS -j oe
#PBS -o ./results_Scenario_11_Random_Stat_Many_Files_One_Proc.$PBS_JOBID
#PBS -l walltime=0:10:00,size=164

cd $PBS_O_WORKDIR
EXECUTABLE="./mdtest"

##############################################################################
########## Change parameters below as needed #################################
########## Note: task == process            ##################################
TPN=4                                    # Tasks per Node
FPT=64                                   # Files per task
ITERS=1                                  # Number of times to run test
VERB="     "                             # Verbose mode "-v -v"
PRE_CREATE=0                             # If true, create 0-length files as specified below accross OSTs
tests="1000"                           # specify target number of files to create in each directory 
dir_list="09 01 04 03 02 06 05 07 08 00" # list of dir names
############# Should not have to change stuff below this line #################

for nfiles in $tests
do
let "nprocs = $nfiles / $FPT"
let "nodes  = $nprocs / $TPN + 1" # round up to nearest # nodes
let "nprocs = $nodes  * $TPN"     # actual # procs
let "mfiles = $nprocs * $FPT"     # actual # files
echo "Starting test with on $nodes nodes, $nprocs processes, $mfiles files per directory"

##########################################################################################################
## 2. Randomly make ten (10) directories. 
##         How are directories made randomly??? Humor the spec writers...
##########################################################################################################
for dir in $dir_list
do
rm -fr ${dir}
mkdir  ${dir}
###########################################################################################
# create 0 length files,  stripe 1, round robin files accross MAX_OSTs OSTs. tune to suit.
###########################################################################################
if [ "$PRE_CREATE" == "1" ]
then
DATA_FILE="mdtest"
date
iost=0
iproc=0
while [ "$iproc" -lt "$nprocs" ]
do
ifile=0
while [ "$ifile" -lt "$FPT" ]
do
lfs setstripe -s 1m -c 1 -i $iost ${dir}/${DATA_FILE}.${iproc}.${ifile}
iost=`expr $iost + 1`
ifile=`expr $ifile + 1`
done
iproc=`expr $iproc + 1`
done
let "$ifile = $nprocs * $FPT"
echo "PRE-CREATED $ifile 0-len files"
fi

date
##########################################################################################################
## 3. Randomly create in parallel one (1) million files in each of the ten (10) directories 
##    using at least one hundred (100) creation threads or processes.
##         OK, Let's create a bunch with random sizes, and then random stat 'em. And we do it with 
##         # of directory parallel launches of mdtest. This ought to scramble things a bit!
##########################################################################################################
# File create, random sizes between 1-64KB, concurrent random stat tests, files only, no directories, $FPT files per task/process
aprun -n ${nprocs} -N $TPN $EXECUTABLE -d ${dir} -n $FPT -i $ITERS  -F -w 1024 -W 65536  -R 0 -k   $VERB &
done
wait

###########################################
# done with file creation. build ordered list
###########################################
let "dircount = 0"
rm -f file_list
touch file_list
for dir in $dir_list
do
ls -1 ${dir}/* >> file_list
let "dircount = dircount + 1"
done
# Randomly shuffle ordered list
let "mfiles = $mfiles * $dircount"
./rshuffle -f file_list -n  $mfiles > file_list_random
##########################################################################################################
##   This is the cold cache case
## 6. Start time counter.
## 7. Serial random walk using readdir() or stat() of all the files in each of the directories in a random order 
##    using only one (1) thread or process (this is the cold cache test).
##    OK, the spec said one (1) process!!!!!
## 8. Stop time counter.
##########################################################################################################
# single process stat() of all files on randomly shuffled file of $mfiles files...dont remove files 
date
aprun -n 1 -N 1 $EXECUTABLE -d . -n $mfiles -i $ITERS  -F -L file_list_random -B 0 -E -k   $VERB 
##########################################################################################################
##   This is the warm cache case
##########################################################################################################
date
aprun -n 1 -N 1 $EXECUTABLE -d . -n $mfiles -i $ITERS  -F -L file_list_random -B 0 -E -k   $VERB 

#date
#lfs getstripe ${DATA_DIR}/*

##########################################################################################################
##     remove files in parallel
##########################################################################################################
# File create, random sizes between 1-64KB, concurrent random stat tests, files only, no directories, $FPT files per task/process
for dir in $dir_list
do
#lfs getstripe ${dir}/*
aprun -n ${nprocs} -N $TPN $EXECUTABLE -d ${dir} -n $FPT -i $ITERS  -F -w 1024 -W 65536  -R 0 -r   $VERB &
done
wait
for dir in $dir_list
do
rmdir ${dir}
done

echo "Finished test with on $nodes nodes, $nprocs processes, $nfiles files"
done
